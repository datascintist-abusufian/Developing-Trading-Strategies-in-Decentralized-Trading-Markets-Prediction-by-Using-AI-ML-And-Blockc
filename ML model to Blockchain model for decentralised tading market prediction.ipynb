{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79696d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ml model convert into blockchain model to predict the outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bf2c7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset (replace 'your_data.csv' with your actual CSV file)\n",
    "df = pd.read_excel('/Users/mdabusufian/Downloads/Market_Indicator_Data_combined.xlsx')\n",
    "\n",
    "# Perform preprocessing steps as shown in the previous response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "240c13fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress warning messages\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Code block that generates warning messages\n",
    "# ...\n",
    "\n",
    "# Reset warning settings to default\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "568859f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date              datetime64[ns]\n",
      "TRADING_VOLUME           float64\n",
      "LIQUIDITY                float64\n",
      "GDP                      float64\n",
      "VOLATILITY               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset (replace 'your_data.csv' with your actual CSV file)\n",
    "df = pd.read_excel('/Users/mdabusufian/Downloads/Market_Indicator_Data_combined.xlsx')\n",
    "\n",
    "# Inspect the dataset's columns and dtypes\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2fc3ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e1eaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load your dataset (replace 'your_data.csv' with your actual CSV file)\n",
    "df = pd.read_excel('/Users/mdabusufian/Downloads/Market_Indicator_Data_combined.xlsx')\n",
    "\n",
    "\n",
    "# Convert the \"Date\" column to numerical values\n",
    "df['Date'] = (df['Date'] - pd.Timestamp('1970-01-01')) // pd.Timedelta('1s')\n",
    "\n",
    "# Handle missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = df_scaled[:, :-1]\n",
    "y = df_scaled[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a8da015",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Develop an ML model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d5932af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model R^2 score: 0.5422962115201089\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "score = model.score(X_test, y_test)\n",
    "print(f\"Model R^2 score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96ac6485",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For R square and RMSE valuses both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4059bc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model RMSE: 0.17802817710736496\n",
      "Model R^2 score: 0.5422962115201089\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"Model RMSE: {rmse}\")\n",
    "\n",
    "# Evaluate the model (R^2 score)\n",
    "score = model.score(X_test, y_test)\n",
    "print(f\"Model R^2 score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eba22af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lower RMSE values indicate better model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0107ba59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets move to blockchaion\n",
    "#Implement a simple blockchain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18469cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import hashlib, time\n",
    "# Define the Block and Blockchain classes as shown in the previous response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54ebd4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress warning messages\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Code block that generates warning messages\n",
    "# ...\n",
    "\n",
    "# Reset warning settings to default\n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "123b47d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset (replace 'your_data.csv' with your actual CSV file)\n",
    "df = pd.read_excel('/Users/mdabusufian/Downloads/Market_Indicator_Data_combined.xlsx')\n",
    "\n",
    "# Select only the \"TRADING_VOLUME\" column and drop missing values\n",
    "df = df[['Date', 'TRADING_VOLUME']].dropna()\n",
    "\n",
    "# Convert the \"Date\" column to numerical values\n",
    "df['Date'] = (df['Date'] - pd.Timestamp('1970-01-01')) // pd.Timedelta('1s')\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = df_scaled[:, :-1]\n",
    "y = df_scaled[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Select a specific row of data and exclude the \"Date\" column\n",
    "# Replace 'row_number' with the index of the row you want to use as input\n",
    "row_number = 0\n",
    "user_input = df.iloc[row_number, 1:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24a1b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset (replace 'your_data.csv' with your actual CSV file)\n",
    "df = pd.read_excel('/Users/mdabusufian/Downloads/Market_Indicator_Data_combined.xlsx')\n",
    "\n",
    "# Select only the \"TRADING_VOLUME\" column and drop missing values\n",
    "df = df[['Date', 'TRADING_VOLUME']].dropna()\n",
    "\n",
    "# Convert the \"Date\" column to numerical values\n",
    "df['Date'] = (df['Date'] - pd.Timestamp('1970-01-01')) // pd.Timedelta('1s')\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(df[['TRADING_VOLUME']])\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X = df[['Date']].values\n",
    "y = df_scaled\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Select a specific row of data and exclude the \"Date\" column\n",
    "# Replace 'row_number' with the index of the row you want to use as input\n",
    "row_number = 0\n",
    "user_input = df.iloc[row_number, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25903b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import time\n",
    "\n",
    "class Block:\n",
    "    def __init__(self, index, transactions, previous_hash):\n",
    "        self.index = index\n",
    "        self.timestamp = time.time()\n",
    "        self.transactions = transactions\n",
    "        self.previous_hash = previous_hash\n",
    "        self.nonce = 0\n",
    "        self.hash = self.compute_hash()\n",
    "\n",
    "    def compute_hash(self):\n",
    "        block_string = f\"{self.index}{self.timestamp}{self.transactions}{self.previous_hash}{self.nonce}\"\n",
    "        return hashlib.sha256(block_string.encode()).hexdigest()\n",
    "\n",
    "    def mine_block(self, difficulty):\n",
    "        while self.hash[:difficulty] != '0' * difficulty:\n",
    "            self.nonce += 1\n",
    "            self.hash = self.compute_hash()\n",
    "\n",
    "class Blockchain:\n",
    "    def __init__(self, difficulty=4):\n",
    "        self.chain = [self.create_genesis_block()]\n",
    "        self.difficulty = difficulty\n",
    "\n",
    "    def create_genesis_block(self):\n",
    "        return Block(index=0, transactions=\"Genesis Block\", previous_hash=\"0\")\n",
    "\n",
    "    def get_latest_block(self):\n",
    "        return self.chain[-1]\n",
    "\n",
    "    def add_block(self, new_block):\n",
    "        new_block.mine_block(self.difficulty)\n",
    "        self.chain.append(new_block)\n",
    "\n",
    "    def make_prediction(self, user_input):\n",
    "        normalized_input = scaler.transform(np.array([user_input]).reshape(1, -1))\n",
    "        prediction = model.predict(normalized_input)\n",
    "        prediction = scaler.inverse_transform(prediction.reshape(1, -1))[0][0]\n",
    "\n",
    "        # Store the prediction in a new block\n",
    "        new_block = Block(\n",
    "            index=len(self.chain),\n",
    "            transactions={'user_input': user_input, 'prediction': prediction},\n",
    "            previous_hash=self.get_latest_block().hash\n",
    "        )\n",
    "        self.add_block(new_block)\n",
    "\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad1a4a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mdabusufian/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 2915.2156820294663\n",
      "Blockchain contents:\n",
      "Genesis Block\n",
      "{'user_input': array([126.262543]), 'prediction': 2915.2156820294663}\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Create a new blockchain instance\n",
    "my_blockchain = Blockchain()\n",
    "\n",
    "# Make a prediction and store it in the blockchain\n",
    "prediction = my_blockchain.make_prediction(user_input)\n",
    "print(f\"Prediction: {prediction}\")\n",
    "\n",
    "# Check the blockchain contents\n",
    "print(\"Blockchain contents:\")\n",
    "for block in my_blockchain.chain:\n",
    "    print(block.transactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d630424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2816.8960812387363\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Suppress warning messages\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "# Make predictions and store them in the blockchain\n",
    "my_blockchain = Blockchain()\n",
    "for index, row in df.iterrows():\n",
    "    user_input = row['TRADING_VOLUME']\n",
    "    prediction = my_blockchain.make_prediction(user_input)\n",
    "\n",
    "# Get the predicted values from the blockchain\n",
    "predicted_values = [block.transactions['prediction'] for block in my_blockchain.chain[1:]]\n",
    "\n",
    "# Get the actual values from the dataset\n",
    "actual_values = df['TRADING_VOLUME'].values\n",
    "\n",
    "# Calculate the RMSE\n",
    "rmse = mean_squared_error(actual_values, predicted_values, squared=False)\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Reset warning settings to default\n",
    "warnings.resetwarnings()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317daa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The RMSE value is for the blockchain model.\n",
    "#It is a measure of how well the model is able to predict the TRADING_VOLUME values for the dataset.\n",
    "#The lower the RMSE value, the better the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46264fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a high RMSE value indicates that the predictions made by the blockchain model are not accurate. \n",
    "#In other words, the model is not performing well in predicting the decentralized trading market based on the input variables. \n",
    "#A lower RMSE value would indicate better predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a75e57e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The amount and volume of the datasets are modest.  The quality and\n",
      "quantity of the data, the machine learning methods and methodologies\n",
      "chosen, and  the success of the blockchain implementation all play a\n",
      "role in whether or not a decent result can be obtained utilising this\n",
      "dataset. It is crucial to test out various models and methods, as well\n",
      "as to continuously monitor and enhance the system's performance.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "text = \"\"\"The amount and volume of the datasets are modest. \n",
    "The quality and quantity of the data, the machine learning methods and methodologies chosen, and \n",
    "the success of the blockchain implementation all play a role in whether or not a decent result can be obtained utilising this dataset.\n",
    "It is crucial to test out various models and methods, as well as to continuously monitor and enhance the system's performance.\"\"\"\n",
    "wrapper = textwrap.TextWrapper(width=70)\n",
    "wrapped_text = wrapper.fill(text)\n",
    "\n",
    "print(wrapped_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "547b0bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date                0\n",
      "TRADING_VOLUME      1\n",
      "LIQUIDITY         114\n",
      "GDP               114\n",
      "VOLATILITY        124\n",
      "dtype: int64\n",
      "Date                0\n",
      "TRADING_VOLUME      1\n",
      "LIQUIDITY         114\n",
      "GDP               114\n",
      "VOLATILITY        124\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the data\n",
    "df = pd.read_excel('/Users/mdabusufian/Downloads/Market_Indicator_Data_combined.xlsx')\n",
    "\n",
    "\n",
    "# check for missing or invalid values\n",
    "print(df.isna().sum())\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e2aea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward fill (ffill): This method fills missing values with the previous value in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84b47f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method='ffill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50a05e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backward fill (bfill): This method fills missing values with the next value in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b69aac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(method='bfill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c4452c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean imputation: This method fills missing values with the mean value of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "555a38b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0g/g88nlxr56dd7_myqsdsldryc0000gn/T/ipykernel_30745/513357919.py:1: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df = df.fillna(df.mean())\n"
     ]
    }
   ],
   "source": [
    "df = df.fillna(df.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15716133",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Median imputation: This method fills missing values with the median value of the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4ca081cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0g/g88nlxr56dd7_myqsdsldryc0000gn/T/ipykernel_30745/3788700817.py:1: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.\n",
      "  df = df.fillna(df.median())\n"
     ]
    }
   ],
   "source": [
    "df = df.fillna(df.median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0dac1f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Proper use of the MinMaxScaler from sklearn.preprocessing to scale the data to a specific range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07185d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TRADING_VOLUME  LIQUIDITY       GDP  VOLATILITY       Date\n",
      "0        0.883740   0.489777  0.089484    0.842417 2022-04-03\n",
      "1        0.858367   0.579926  0.129966    0.875593 2022-04-04\n",
      "2        0.877169   0.638476  0.079398    0.914692 2022-04-05\n",
      "3        0.919408   0.619888  0.182110    0.906398 2022-04-06\n",
      "4        0.908453   0.563197  0.082315    0.887441 2022-04-07\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_excel('/Users/mdabusufian/Downloads/Market_Indicator_Data_combined.xlsx')\n",
    "\n",
    "# Initialize a scaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Scale your data\n",
    "scaled_data = scaler.fit_transform(df[['TRADING_VOLUME', 'LIQUIDITY', 'GDP', 'VOLATILITY']])\n",
    "\n",
    "# Create a new dataframe with the scaled data\n",
    "df_scaled = pd.DataFrame(scaled_data, columns=['TRADING_VOLUME', 'LIQUIDITY', 'GDP', 'VOLATILITY'])\n",
    "\n",
    "# Concatenate the date column to the new dataframe\n",
    "df_scaled['Date'] = df['Date']\n",
    "\n",
    "# Output the scaled dataframe\n",
    "print(df_scaled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "068e8ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to convert a column to float64 datatype in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab39222f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date              datetime64[ns]\n",
      "TRADING_VOLUME           float64\n",
      "LIQUIDITY                float64\n",
      "GDP                      float64\n",
      "VOLATILITY               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_excel('/Users/mdabusufian/Downloads/Market_Indicator_Data_combined.xlsx')\n",
    "\n",
    "# Convert a specific column to float64\n",
    "df['TRADING_VOLUME'] = df['TRADING_VOLUME'].astype('float64')\n",
    "\n",
    "\n",
    "# Check the datatype of the column\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac6c871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a copy of the dataframe without the datetime column\n",
    "df_numeric = df.drop(['Date'], axis=1)\n",
    "\n",
    "# Scale the numeric columns\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = pd.DataFrame(scaler.fit_transform(df_numeric), columns=df_numeric.columns)\n",
    "\n",
    "# Merge the datetime column back in\n",
    "df_scaled['Date'] = df['Date']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2796149",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
